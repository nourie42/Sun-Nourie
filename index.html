# sunoco_prospector.py
# ------------------------------------------------------------
# FastAPI web app to find Sunoco prospects using Google Maps Platform,
# Street View imagery, heuristic image analysis, scoring, and Excel export.
# ------------------------------------------------------------
import os
import io
import math
import time
import uuid
import base64
import threading
from datetime import datetime

import requests
import numpy as np
import pandas as pd
from PIL import Image
import cv2

from fastapi import FastAPI, Request, BackgroundTasks, Query
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse, FileResponse, Response
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field

# ------------------- Configuration -------------------
GOOGLE_KEY = os.getenv("GOOGLE_MAPS_API_KEY", "")
if not GOOGLE_KEY:
    print("WARNING: GOOGLE_MAPS_API_KEY not set. Set it before running.")

USER_AGENT = "SunocoProspector/1.0 (+https://example.local)"

# Limits and knobs
MAX_GRID_POINTS = 25            # cap to keep queries reasonable
NEARBY_RADIUS_M = 50000         # max allowed by Places NearbySearch
PLACES_PAGE_SIZE = 60           # Places will page internally; we iterate until exhaustion or cap
DEFAULT_MAX_PROSPECTS = 50
SV_IMAGE_SIZE = "640x640"       # Static Street View image size
SV_FOV = 90
SV_PITCH = 0
SV_HEADINGS = [0, 60, 120, 180, 240, 300]  # try multiple headings to increase chance of capturing pumps
DOWNLOAD_TIMEOUT = 12

# Heuristic scoring weights (tune as needed)
WEIGHT_BRAND_IMG_AGE = 0.45
WEIGHT_DISPENSER_AGE = 0.25
WEIGHT_CANOPY_AGE = 0.30

CURRENT_YEAR = datetime.utcnow().year

# ------------------- FastAPI app -------------------
app = FastAPI(title="Sunoco Prospector", version="1.0.0")

# In-memory job store (simple single-instance queue)
JOBS = {}  # job_id -> dict(status, progress, total, rows(list), started, finished, error)

# ------------------- Models -------------------
class SearchRequest(BaseModel):
    city: str = Field(..., description="City to search (can include state)")
    radius_miles: float = Field(..., gt=0, le=100, description="Radius in miles (<=100 recommended)")
    max_prospects: int = Field(DEFAULT_MAX_PROSPECTS, gt=0, le=500)
    include_existing_sunoco: bool = Field(False, description="Include stations that already appear to be Sunoco")
    throttle_ms: int = Field(200, description="Delay between API calls to stay polite with quotas")

# ------------------- Utility: Google APIs -------------------
def geocode_city(city: str):
    url = "https://maps.googleapis.com/maps/api/geocode/json"
    params = {"address": city, "key": GOOGLE_KEY}
    r = requests.get(url, params=params, headers={"User-Agent": USER_AGENT}, timeout=DOWNLOAD_TIMEOUT)
    r.raise_for_status()
    data = r.json()
    if data.get("status") != "OK" or not data.get("results"):
        return None
    loc = data["results"][0]["geometry"]["location"]
    return {"lat": loc["lat"], "lng": loc["lng"]}

def nearby_gas_stations(lat: float, lng: float, radius_m: int, pagetoken: str = None):
    """Call Places Nearby Search for gas stations around a point."""
    url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"
    params = {
        "key": GOOGLE_KEY,
        "location": f"{lat},{lng}",
        "radius": radius_m,
        "type": "gas_station",
    }
    if pagetoken:
        params["pagetoken"] = pagetoken
    r = requests.get(url, params=params, headers={"User-Agent": USER_AGENT}, timeout=DOWNLOAD_TIMEOUT)
    r.raise_for_status()
    return r.json()

def place_details(place_id: str):
    url = "https://maps.googleapis.com/maps/api/place/details/json"
    params = {"place_id": place_id, "key": GOOGLE_KEY, "fields": "place_id,name,geometry,formatted_address"}
    r = requests.get(url, params=params, headers={"User-Agent": USER_AGENT}, timeout=DOWNLOAD_TIMEOUT)
    r.raise_for_status()
    return r.json()

def street_view_metadata(lat: float, lng: float):
    url = "https://maps.googleapis.com/maps/api/streetview/metadata"
    params = {
        "location": f"{lat},{lng}",
        "key": GOOGLE_KEY,
        "radius": 60  # allow small snap radius to pick nearest pano
    }
    r = requests.get(url, params=params, headers={"User-Agent": USER_AGENT}, timeout=DOWNLOAD_TIMEOUT)
    r.raise_for_status()
    return r.json()

def street_view_image_bytes(lat: float, lng: float, heading: int):
    url = "https://maps.googleapis.com/maps/api/streetview"
    params = {
        "size": SV_IMAGE_SIZE,
        "location": f"{lat},{lng}",
        "heading": heading,
        "fov": SV_FOV,
        "pitch": SV_PITCH,
        "key": GOOGLE_KEY
    }
    r = requests.get(url, params=params, headers={"User-Agent": USER_AGENT}, timeout=DOWNLOAD_TIMEOUT)
    r.raise_for_status()
    return r.content

# ------------------- Geometry helpers -------------------
def miles_to_meters(mi: float) -> int:
    return int(round(mi * 1609.344))

def grid_points(center_lat, center_lng, radius_m, n_points_max=MAX_GRID_POINTS):
    """
    Create a simple hex-like grid of query points covering the circle of radius_m.
    We step ~radius/2 to ensure decent coverage with few points.
    """
    # approx: 1 deg lat ~ 111,320 m; 1 deg lng ~ 111,320 * cos(lat)
    lat_meter = 111320.0
    lng_meter = 111320.0 * math.cos(math.radians(center_lat))
    step = radius_m / 2.5
    coords = []
    # simple square grid clipped to circle
    for dy in np.arange(-radius_m, radius_m + 1, step):
        for dx in np.arange(-radius_m, radius_m + 1, step):
            if dx*dx + dy*dy > radius_m*radius_m:
                continue
            lat = center_lat + (dy / lat_meter)
            lng = center_lng + (dx / lng_meter)
            coords.append((lat, lng))
            if len(coords) >= n_points_max:
                return coords
    return coords

# ------------------- CV Heuristics -------------------
def _np_img_from_bytes(b: bytes):
    arr = np.frombuffer(b, dtype=np.uint8)
    img = cv2.imdecode(arr, cv2.IMREAD_COLOR)  # BGR
    return img

def estimate_brand_image_age_years(img_bgr: np.ndarray) -> float:
    """
    Proxy for "brand image age" using color fading & wear:
    - Convert to HSV, compute mean saturation; lower sat -> older/faded
    - Edge density (Canny edges) high + low saturation -> likely older/faded panels/signs.
    Returns estimated *years since last refresh* in [0, 20] (cap).
    """
    if img_bgr is None:
        return 10.0
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    sat = hsv[:, :, 1].astype(np.float32) / 255.0
    mean_sat = float(np.mean(sat))
    # edge density
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 80, 160)
    edge_density = np.count_nonzero(edges) / edges.size
    # combine: lower saturation & higher edge density => older
    age = (1.0 - mean_sat) * 14.0 + edge_density * 8.0
    age = max(0.0, min(age, 20.0))
    return age

def _find_bright_rectangles(img_gray: np.ndarray):
    """
    Heuristic 'screen' detector: find bright rectangular regions (e.g., pump displays).
    Returns list of bounding boxes (x,y,w,h).
    """
    blur = cv2.GaussianBlur(img_gray, (5,5), 0)
    # threshold bright areas
    thr = cv2.threshold(blur, 200, 255, cv2.THRESH_BINARY)[1]
    # morphology to merge
    kernel = np.ones((3,3), np.uint8)
    thr = cv2.morphologyEx(thr, cv2.MORPH_CLOSE, kernel, iterations=2)
    contours, _ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    rects = []
    for c in contours:
        x,y,w,h = cv2.boundingRect(c)
        if w*h < 150:  # ignore tiny
            continue
        ar = w / (h + 1e-6)
        if 0.2 < ar < 4.5:
            rects.append((x,y,w,h))
    return rects

def estimate_dispenser_year(img_bgr: np.ndarray) -> int:
    """
    Extremely simple, conservative estimate of dispenser 'era':
    - Look for large bright rectangular displays (post-1990 digital).
    - Many small bright windows and very small/no displays => pre-1990 mechanical.
    - If unsure, assume >= 1990 to avoid false exclusion.
    Returns a year estimate (e.g., 1980, 1995, 2005, 2015).
    """
    if img_bgr is None:
        return 2000
    h, w = img_bgr.shape[:2]
    # Focus on lower 2/3 (where pumps likely are)
    roi = img_bgr[int(h*0.33):, :]
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    rects = _find_bright_rectangles(gray)
    # Count and size stats
    areas = [rw*rh for (_,_,rw,rh) in rects]
    large_displays = sum(1 for a in areas if a > 1200)
    small_displays = sum(1 for a in areas if 200 < a <= 1200)
    total = len(rects)

    # Heuristics
    if total == 0:
        return 2000  # unknown -> modern enough
    if large_displays >= 1 and total <= 3:
        # likely modern digital (LCD), post 2000
        return 2005 if large_displays == 1 else 2012
    if small_displays >= 4 and large_displays == 0:
        # many small windows -> older mechanical/early electronic
        return 1985
    # mixed signals
    return 1995

def estimate_canopy_age_years(img_bgr: np.ndarray) -> float:
    """
    Canopy 'age' proxy using top band: look for horizontal band, measure yellowing and panel seams.
    Returns years in [0, 30].
    """
    if img_bgr is None:
        return 12.0
    h, w = img_bgr.shape[:2]
    top = img_bgr[: int(h*0.25), :]
    hsv = cv2.cvtColor(top, cv2.COLOR_BGR2HSV)
    sat = hsv[:, :, 1].astype(np.float32) / 255.0
    val = hsv[:, :, 2].astype(np.float32) / 255.0
    mean_sat = float(np.mean(sat))
    mean_val = float(np.mean(val))

    # seam detection via vertical edges in the top area
    gray = cv2.cvtColor(top, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 70, 140)
    v_edges = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)  # vertical gradients
    seam_strength = float(np.mean(np.abs(v_edges))) / 255.0
    edge_density = np.count_nonzero(edges) / edges.size

    # older canopy: lower saturation, lower brightness, higher seams/edges
    age = (1.0 - mean_sat) * 18.0 + (0.7 - mean_val) * 8.0 + (seam_strength + edge_density) * 6.0
    age = max(0.0, min(age, 30.0))
    return age

def composite_score(brand_age_yrs: float, dispenser_year: int, canopy_age_yrs: float) -> float:
    """Higher score => better prospect (older look, but not too ancient pumps)."""
    disp_age = max(0, CURRENT_YEAR - dispenser_year)
    score = (brand_age_yrs * WEIGHT_BRAND_IMG_AGE
             + disp_age * WEIGHT_DISPENSER_AGE
             + canopy_age_yrs * WEIGHT_CANOPY_AGE)
    return float(score)

# ------------------- Processing pipeline -------------------
def analyze_station(place: dict, throttle_ms: int):
    """
    For a single place: pull street view metadata; try several headings; pick best frame;
    compute heuristics; return a summary row (or None if excluded).
    """
    name = place.get("name", "")
    address = place.get("vicinity") or place.get("formatted_address") or ""
    place_id = place.get("place_id")
    loc = place["geometry"]["location"]
    lat, lng = loc["lat"], loc["lng"]

    # Street View metadata
    meta = street_view_metadata(lat, lng)
    if meta.get("status") != "OK":
        return None
    sv_date = meta.get("date")  # e.g., "2019-07"
    # choose an image frame that maximizes chance of pumps
    best_frame = None
    best_score = -999
    best_heading = None
    for hdg in SV_HEADINGS:
        try:
            img_bytes = street_view_image_bytes(lat, lng, hdg)
            img = _np_img_from_bytes(img_bytes)
            # simple heuristic 'pump-likeliness': count bright rectangles in lower portion
            h, w = img.shape[:2]
            roi = cv2.cvtColor(img[int(h*0.33):, :], cv2.COLOR_BGR2GRAY)
            rects = _find_bright_rectangles(roi)
            pumpish = len(rects)
            if pumpish > best_score:
                best_score = pumpish
                best_frame = img
                best_heading = hdg
        except Exception:
            continue
        time.sleep(throttle_ms / 1000.0)

    if best_frame is None:
        return None

    brand_age_yrs = estimate_brand_image_age_years(best_frame)
    dispenser_year = estimate_dispenser_year(best_frame)
    canopy_age_yrs = estimate_canopy_age_years(best_frame)

    # Exclude dispensers older than 1990
    if dispenser_year < 1990:
        return None

    score = composite_score(brand_age_yrs, dispenser_year, canopy_age_yrs)
    return {
        "place_id": place_id,
        "name": name,
        "address": address,
        "lat": lat,
        "lng": lng,
        "street_view_date": sv_date,
        "best_heading": best_heading,
        "brand_image_age_years": round(brand_age_yrs, 1),
        "dispenser_year_est": int(dispenser_year),
        "canopy_age_years": round(canopy_age_yrs, 1),
        "score": round(score, 2),
    }

def run_job(job_id: str, payload: SearchRequest):
    try:
        JOBS[job_id] = {"status": "running", "progress": 0, "total": 0, "rows": [], "started": time.time(), "finished": None, "error": None}
        # Geocode
        loc = geocode_city(payload.city)
        if not loc:
            JOBS[job_id].update(status="error", error=f"Could not geocode '{payload.city}'")
            return
        center_lat, center_lng = loc["lat"], loc["lng"]
        radius_m = miles_to_meters(payload.radius_miles)

        # Build grid of query points
        points = grid_points(center_lat, center_lng, radius_m)
        seen_place_ids = set()
        candidates = []

        # Query places around each grid point
        for (plat, plng) in points:
            pt_page = None
            pages = 0
            while True:
                data = nearby_gas_stations(plat, plng, min(radius_m, NEARBY_RADIUS_M), pt_page)
                status = data.get("status")
                if status not in ("OK", "ZERO_RESULTS"):
                    break
                for res in data.get("results", []):
                    pid = res.get("place_id")
                    if not pid or pid in seen_place_ids:
                        continue
                    name = res.get("name", "")
                    # Exclude existing Sunoco unless asked otherwise
                    if not payload.include_existing_sunoco and "sunoco" in name.lower():
                        continue
                    seen_place_ids.add(pid)
                    # Add enriched candidate
                    candidates.append({
                        "place_id": pid,
                        "name": name,
                        "vicinity": res.get("vicinity"),
                        "geometry": res.get("geometry"),
                    })
                pt_page = data.get("next_page_token")
                pages += 1
                if not pt_page or pages >= 3:
                    break
                time.sleep(2)  # Places requires short delay before next page
            time.sleep(payload.throttle_ms / 1000.0)

        JOBS[job_id]["total"] = len(candidates)

        # Analyze each candidate with Street View heuristics
        rows = []
        for idx, c in enumerate(candidates, start=1):
            if len(rows) >= payload.max_prospects:
                break
            try:
                row = analyze_station(c, payload.throttle_ms)
                if row:
                    rows.append(row)
            except Exception:
                pass
            JOBS[job_id]["progress"] = idx

        # Rank by score (desc)
        rows = sorted(rows, key=lambda r: r["score"], reverse=True)
        # Keep top N (may be fewer than requested if filtering removes many)
        rows = rows[: payload.max_prospects]

        JOBS[job_id].update(status="done", rows=rows, finished=time.time())
    except Exception as e:
        JOBS[job_id].update(status="error", error=str(e), finished=time.time())

# ------------------- API Routes -------------------
@app.get("/", response_class=HTMLResponse)
def index():
    return HTML_PAGE

@app.post("/start_search")
async def start_search(req: SearchRequest):
    if not GOOGLE_KEY:
        return JSONResponse({"error": "GOOGLE_MAPS_API_KEY is not set on the server."}, status_code=400)
    job_id = uuid.uuid4().hex
    t = threading.Thread(target=run_job, args=(job_id, req), daemon=True)
    t.start()
    return {"job_id": job_id}

@app.get("/status/{job_id}")
def get_status(job_id: str):
    job = JOBS.get(job_id)
    if not job:
        return JSONResponse({"error": "Job not found"}, status_code=404)
    return {
        "status": job["status"],
        "progress": job["progress"],
        "total": job["total"],
        "rows_ready": len(job.get("rows", [])),
        "error": job.get("error"),
    }

@app.get("/results/{job_id}")
def get_results(job_id: str):
    job = JOBS.get(job_id)
    if not job:
        return JSONResponse({"error": "Job not found"}, status_code=404)
    if job["status"] != "done":
        return JSONResponse({"error": "Job not finished"}, status_code=400)
    return {"rows": job["rows"]}

@app.get("/export/{job_id}.xlsx")
def export_excel(job_id: str):
    job = JOBS.get(job_id)
    if not job or job["status"] != "done":
        return JSONResponse({"error": "Job not finished or not found"}, status_code=400)
    df = pd.DataFrame(job["rows"])
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="prospects", index=False)
    buf.seek(0)
    headers = {"Content-Disposition": f'attachment; filename="sunoco_prospects_{job_id}.xlsx"'}
    return Response(content=buf.read(), media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", headers=headers)

@app.get("/streetview/{job_id}/{idx}")
def get_streetview_frame(job_id: str, idx: int, heading: int = 0):
    """
    Optional on-demand image proxy by lat/lng and heading if you want to show raw frames.
    Here we retrieve the stored row's lat/lng and return a proxied Street View image.
    """
    job = JOBS.get(job_id)
    if not job or job["status"] != "done":
        return JSONResponse({"error": "Job not finished or not found"}, status_code=400)
    rows = job.get("rows", [])
    if idx < 0 or idx >= len(rows):
        return JSONResponse({"error": "Index out of range"}, status_code=400)
    r = rows[idx]
    lat, lng = r["lat"], r["lng"]
    img_bytes = street_view_image_bytes(lat, lng, heading or r.get("best_heading", 0))
    return Response(content=img_bytes, media_type="image/jpeg")

# ------------------- HTML UI -------------------
HTML_PAGE = """
<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Sunoco Prospector</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root { --bg: #0f172a; --card: #111827; --text: #e5e7eb; --muted:#9ca3af; --accent:#38bdf8; --ok:#22c55e; --warn:#f59e0b; --err:#ef4444; }
    body { margin:0; font: 16px/1.5 system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial; background:var(--bg); color:var(--text); }
    header { padding: 24px; text-align:center; }
    .wrap { max-width: 1100px; margin: 0 auto; padding: 0 16px 40px; }
    .card { background: var(--card); border: 1px solid #1f2937; border-radius: 12px; padding: 16px; box-shadow: 0 10px 30px rgba(0,0,0,.3); }
    label { display:block; margin: 10px 0 6px; color: var(--muted); }
    input[type=text], input[type=number] {
      width: 100%; padding: 10px 12px; border:1px solid #374151; border-radius: 8px; background:#0b1220; color:var(--text);
    }
    .row { display:flex; gap:16px; }
    .col { flex:1; }
    button {
      background: linear-gradient(180deg, #38bdf8, #0ea5e9); color:white; border:none; border-radius: 10px; padding: 10px 16px;
      font-weight: 600; cursor:pointer; box-shadow: 0 6px 18px rgba(14,165,233,.35);
    }
    button:disabled { opacity:.6; cursor:not-allowed; }
    .progress { height: 10px; background:#0b1220; border:1px solid #1f2937; border-radius: 999px; overflow:hidden; }
    .bar { height:100%; background: linear-gradient(90deg, #22d3ee, #0ea5e9); width:0%; transition: width .3s; }
    table { width:100%; border-collapse: collapse; margin-top: 16px; }
    th, td { border-bottom: 1px solid #1f2937; padding: 10px; text-align:left; }
    th { color: #a1a1aa; font-weight: 600; }
    .pill { display:inline-block; padding:2px 8px; border-radius:999px; font-size:12px; }
    .muted { color: var(--muted); }
    .powered { font-size: 12px; color: #94a3b8; text-align: right; margin-top: 8px; }
    .hint { font-size: 12px; color: #94a3b8; margin-top: 8px; }
    .ok { color: var(--ok); }
    .warn { color: var(--warn); }
    .err { color: var(--err); }
  </style>
</head>
<body>
  <header>
    <h1>Sunoco Prospector</h1>
    <div class="muted">Find top candidate stations by image age (brand, dispensers, canopy), then export to Excel.</div>
  </header>
  <div class="wrap">
    <div class="card">
      <form id="f">
        <label>City (you can include state)</label>
        <input type="text" id="city" placeholder="e.g., Raleigh, NC" required />

        <div class="row">
          <div class="col">
            <label>Radius (miles)</label>
            <input type="number" step="0.1" min="0.1" max="100" id="radius" value="20" required />
          </div>
          <div class="col">
            <label>How many prospects?</label>
            <input type="number" min="1" max="500" id="maxp" value="50" />
          </div>
        </div>

        <div style="margin:10px 0;">
          <label><input type="checkbox" id="includeSunoco" /> Include stations that already appear to be Sunoco</label>
        </div>

        <div class="row" style="align-items:flex-end;">
          <div class="col">
            <label>API call throttle (ms)</label>
            <input type="number" min="0" max="1000" id="throttle" value="200" />
          </div>
          <div class="col" style="text-align:right;">
            <button id="go">Start</button>
          </div>
        </div>
      </form>

      <div class="hint">This tool uses the Google Maps Platform (Places, Geocoding, Street View) with proper attribution. It relies on visual heuristics, which you can later replace with your own ML models.</div>
      <div class="powered">Powered by Google</div>
    </div>

    <div class="card" style="margin-top:16px;">
      <div class="row" style="align-items:center;">
        <div class="col">
          <div>Status: <span id="status" class="pill">idle</span></div>
        </div>
        <div class="col" style="text-align:right;">
          <a id="download" class="muted" href="#" style="display:none;">Download Excel</a>
        </div>
      </div>
      <div class="progress" style="margin-top:8px;">
        <div class="bar" id="bar"></div>
      </div>
      <div id="msg" class="hint"></div>
      <div id="results"></div>
    </div>
  </div>

<script>
const f = document.getElementById('f');
const go = document.getElementById('go');
const statusEl = document.getElementById('status');
const bar = document.getElementById('bar');
const msg = document.getElementById('msg');
const resultsEl = document.getElementById('results');
const dl = document.getElementById('download');

let jobId = null;
let pollTimer = null;

function setStatus(txt, cls) {
  statusEl.textContent = txt;
  statusEl.className = 'pill ' + (cls || '');
}

function renderTable(rows) {
  if (!rows || rows.length === 0) {
    resultsEl.innerHTML = '<div class="muted">No results.</div>';
    return;
  }
  let html = '<table><thead><tr>' +
    '<th>#</th><th>Name</th><th>Address</th><th>SV Date</th>' +
    '<th>Brand Img Age (yrs)</th><th>Dispenser Year</th><th>Canopy Age (yrs)</th><th>Score</th>' +
    '</tr></thead><tbody>';
  rows.forEach((r, i) => {
    html += `<tr>
      <td>${i+1}</td>
      <td>${r.name}</td>
      <td>${r.address || ''}</td>
      <td>${r.street_view_date || ''}</td>
      <td>${r.brand_image_age_years}</td>
      <td>${r.dispenser_year_est}</td>
      <td>${r.canopy_age_years}</td>
      <td><strong>${r.score}</strong></td>
    </tr>`;
  });
  html += '</tbody></table>';
  resultsEl.innerHTML = html;
}

async function poll() {
  if (!jobId) return;
  try {
    const r = await fetch('/status/' + jobId);
    const s = await r.json();
    if (s.error) { setStatus('error', 'err'); msg.textContent = s.error; clearInterval(pollTimer); return; }
    const total = Math.max(1, s.total || 1);
    const pct = Math.round(100 * (s.progress || 0) / total);
    bar.style.width = pct + '%';
    msg.textContent = `Progress: ${s.progress} of ${s.total} candidates processed. Rows ready: ${s.rows_ready}.`;
    if (s.status === 'running') {
      setStatus('running', 'warn');
    } else if (s.status === 'done') {
      setStatus('done', 'ok');
      clearInterval(pollTimer);
      const rr = await fetch('/results/' + jobId);
      const data = await rr.json();
      renderTable(data.rows);
      dl.style.display = 'inline';
      dl.href = '/export/' + jobId + '.xlsx';
      dl.textContent = 'Export Excel';
    } else if (s.status === 'error') {
      setStatus('error', 'err');
      msg.textContent = s.error || 'Unknown error';
      clearInterval(pollTimer);
    }
  } catch (e) {
    setStatus('error', 'err');
    msg.textContent = 'Failed to poll status.';
    clearInterval(pollTimer);
  }
}

f.addEventListener('submit', async (e) => {
  e.preventDefault();
  resultsEl.innerHTML = '';
  dl.style.display = 'none';
  setStatus('starting', 'warn');
  bar.style.width = '0%';
  msg.textContent = '';

  const body = {
    city: document.getElementById('city').value.trim(),
    radius_miles: parseFloat(document.getElementById('radius').value),
    max_prospects: parseInt(document.getElementById('maxp').value, 10),
    include_existing_sunoco: document.getElementById('includeSunoco').checked,
    throttle_ms: parseInt(document.getElementById('throttle').value, 10),
  };

  try {
    const r = await fetch('/start_search', {
      method:'POST', headers:{'Content-Type':'application/json'},
      body: JSON.stringify(body)
    });
    const j = await r.json();
    if (j.error) { setStatus('error', 'err'); msg.textContent = j.error; return; }
    jobId = j.job_id;
    setStatus('running', 'warn');
    pollTimer = setInterval(poll, 1200);
    poll();
  } catch (err) {
    setStatus('error', 'err');
    msg.textContent = 'Failed to start search.';
  }
});
</script>
</body>
</html>
"""

# End of file

